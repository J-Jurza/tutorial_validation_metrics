# Tutorial: Validation Metrics ðŸ“ŠðŸŽ“

This repository contains Jupyter notebooks that serve as a tutorial for understanding and applying common evaluation metrics in machine learning. These metrics are crucial for assessing the performance of your models and making informed decisions about model selection, tuning, and deployment. The tutorial covers metrics for both classification and regression models, providing a comprehensive overview of how to evaluate different types of machine learning models.

## Notebooks ðŸ““

1. **classification_metrics.ipynb** ðŸ“Š
    - This notebook delves into the essential metrics for classification models. We'll cover when to use each metric, their advantages and disadvantages, and how to implement them. By the end of this notebook, you'll be equipped with the knowledge to assess your classification models effectively.

2. **regression_metrics.ipynb** ðŸ§®
    - Shifting our focus to regression models, this notebook explores the key metrics for evaluating these types of models. Similar to the classification metrics notebook, we'll discuss when to use each metric, their pros and cons, and how to implement them.

## Supporting Articles ðŸ“š
Check out my Medium article on validation metrics:
- [Mastering Validation Metrics: Evaluate Your Models Like a Pro](https://medium.com/@h.jurza/mastering-validation-metrics-evaluate-your-models-like-a-pro-4fda25abe3cb)

## Getting Started ðŸš€

To get started, clone this repository to your local machine and install the necessary dependencies.

```bash
git clone https://github.com/yourusername/tutorial_validation_metrics.git
cd tutorial_validation_metrics
```

Then, you can open the notebooks in Jupyter Notebook or Jupyter Lab and run the cells to follow along with the tutorial.

```bash
jupyter notebook
```


## Contact ðŸ“§

If you have any questions or feedback, please feel free to reach out. Happy coding and learning! ðŸ’»ðŸŽ“
